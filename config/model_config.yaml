training:
  test_size: 0.2
  random_state: 42
  stratify: true
  temporal_validation: false  # Set to true if data has year column
  temporal_cutoff_year: 2024

class_balancing:
  method: 'class_weights'  # Options: 'smote', 'class_weights', 'none'
  smote_k_neighbors: 5
  smote_sampling_strategy: 'auto'

hyperparameter_tuning:
  enabled: true
  method: 'randomized'  # Options: 'grid', 'randomized', 'none'
  n_iter: 30  # Reduced from 50 for faster training
  cv_folds: 3  # Reduced from 5 for faster training
  scoring: 'roc_auc'
  n_jobs: -1

models:
  random_forest:
    enabled: true
    params:
      n_estimators: [100, 200, 300]
      max_depth: [10, 20, 30, None]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ['sqrt', 'log2']
      class_weight: ['balanced', 'balanced_subsample']
    
  xgboost:
    enabled: true
    params:
      n_estimators: [100, 200, 300]
      max_depth: [3, 5, 7]
      learning_rate: [0.01, 0.05, 0.1]
      subsample: [0.8, 1.0]
      colsample_bytree: [0.8, 1.0]
      
  logistic_regression:
    enabled: true
    params:
      C: [0.01, 0.1, 1.0, 10.0]
      penalty: ['l2']
      solver: ['lbfgs']
      max_iter: [2000]
      class_weight: ['balanced']

ensemble:
  enabled: true
  weighting_method: 'performance'  # Options: 'equal', 'performance'
  confidence_threshold: 0.7

shap:
  enabled: true
  background_samples: 100
  save_explainer: true

output:
  model_dir: 'models'
  save_individual_models: true
  save_ensemble: true
  save_shap: true
  report_dir: 'docs'
